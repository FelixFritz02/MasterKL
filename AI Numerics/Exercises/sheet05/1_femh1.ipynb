{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from utils import gen_example, get_laplacian_grid_1d\n",
    "from scipy.sparse import identity, kron, diags_array\n",
    "from qpsolvers import solve_qp\n",
    "import clarabel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MJUe",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "# FEM-H1\n",
    "\n",
    "In this notebook, we will showcase the FEM-H1 method. Let us generate some noisy data to denoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vblA",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_noisy = gen_example(noise=10.)\n",
    "plt.plot(X_noisy)\n",
    "plt.plot(X)\n",
    "plt.legend([\"noisy\", \"clean\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bkHC",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Let us implement an object to perform FEMH1 denoising. Recall that the loss function for FEMH1 is\n",
    "$$\\mathcal{L}_\\text{FEMH1} =\\sum_{d,t,k=1}^{D,T,K}\\Gamma_{k,t}(X_{d,t}-C_{d,k})^2+\\varepsilon^2\\sum_{k,t=1}^{K,T-1}(\\Gamma_{k,t+1}-\\Gamma_{k,t})^2$$\n",
    "with the following constraints:\n",
    "$$\\forall~t,k:0\\leq \\Gamma_{k,t} \\leq 1$$\n",
    "and\n",
    "$$\\forall ~t: \\sum_{k=1}^K \\Gamma_{k,t}=1.$$\n",
    "\n",
    "As such, we can extend our k-means code to include the modifications.\n",
    "In particular, the additional term does not lead to change in the solution of the $C$ step, but only in the $\\Gamma$ one. This problem is now a QP problem.\n",
    "\n",
    "## $\\varepsilon$ parameter\n",
    "This parameter controls *how strongly* the smoothness should be enforced. We will later see the practical effects of choosing specific values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lEQa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class femh1_demo:\n",
    "    def __init__(self,K,epsilon,max_iters=200,tol=1e-8):\n",
    "        self.K = K\n",
    "        self.epsilon=epsilon\n",
    "        self.max_iters = max_iters\n",
    "        self.tol = tol\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"I am a FEMH1 model with K=%d and epsilon %.2e\" % (self.K, self.epsilon)\n",
    "\n",
    "    def fit(self,X):\n",
    "\n",
    "        T = X.shape[0]\n",
    "\n",
    "        # As with kmeans, we create centroids and affiliations\n",
    "        self.S = X[np.random.randint(0,X.shape[0], self.K)]\n",
    "        self.G = np.zeros((X.shape[0], self.K))\n",
    "\n",
    "        self.HG = (2*self.epsilon*kron(identity(self.K), get_laplacian_grid_1d(T))).tocsr()\n",
    "\n",
    "        # Variables needed for QP problem\n",
    "        self.A = kron(np.ones(self.K), identity(T))\n",
    "        self.b = np.ones(T)\n",
    "\n",
    "        # Loop\n",
    "        self.hist_C = []\n",
    "        self.hist_G = []\n",
    "\n",
    "        i = 0\n",
    "        delta = np.inf\n",
    "        prev_error = np.inf\n",
    "        while i<self.max_iters and delta>self.tol:\n",
    "\n",
    "            i+=1\n",
    "\n",
    "            # Update affiliations\n",
    "            self.errors = (np.kron(np.ones((self.K)), X) - np.kron(self.S, np.ones((T))))**2\n",
    "            self.errors /= T\n",
    "\n",
    "            self.gamma_vec = solve_qp(\n",
    "                self.HG, self.errors,A=self.A,b=self.b,lb=np.zeros(T*self.K),\n",
    "                solver=\"clarabel\", initvals=self.G.T.flatten()\n",
    "            )\n",
    "            self.G = self.gamma_vec.reshape(self.K, T).T\n",
    "\n",
    "            # Update centroids\n",
    "            S = 0 #TODO: fix here          \n",
    "\n",
    "        self.denoised = (self.S.reshape(1,-1) @ self.G.T).flatten()\n",
    "        self.L_lin = np.dot(self.errors, self.gamma_vec)\n",
    "        self.L_quad = np.dot((self.HG/(self.epsilon*2)) @ self.gamma_vec, self.gamma_vec)\n",
    "        self.L = self.L_lin + self.epsilon*self.L_quad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PKri",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = femh1_demo(K=2, epsilon=1e-1)\n",
    "m.fit(X_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Xref",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "The affiliations ($\\Gamma$) are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SFPL",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(m.G.T, aspect=\"auto\", interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BYtC",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "And the denoised trace is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RGSE",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_noisy)\n",
    "plt.plot(m.denoised)\n",
    "plt.plot(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Kclp",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Selection of $\\varepsilon$\n",
    "In the following cell, you can interactively change epsilon and observe the effects on the denoising. Note how by increasing the regularization strength (i.e., with $\\varepsilon \\rightarrow \\infty$), we obtain progressively smooth denoised traces, while for $\\varepsilon \\rightarrow 0$ we obtain the k-means solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hstk",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_e = femh1_demo(K=2, epsilon=1e-1)\n",
    "m_e.fit(X_noisy)\n",
    "plt.plot(X_noisy)\n",
    "plt.plot(m_e.denoised)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nWHF",
   "metadata": {},
   "source": [
    "### Practical selection of $\\varepsilon$\n",
    "As for k-means, if we don't know which parameter to choose a-priori, we can explore different potential values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iLit",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = np.logspace(-7,1,10)\n",
    "\n",
    "errors = np.zeros(len(epsilons))\n",
    "errors_l = np.zeros_like(errors)\n",
    "errors_q = np.zeros_like(errors)\n",
    "\n",
    "# write the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZHCJ",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(errors_q, errors_l)\n",
    "plt.scatter(errors_q, errors_l)\n",
    "plt.ylabel(\"Reconstruction error\")\n",
    "plt.xlabel(\"Smoothness error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ROlb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epsilons, errors)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.ylabel('error')\n",
    "plt.xlabel(r'$\\varepsilon$')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
