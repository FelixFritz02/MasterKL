{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f55f1b",
   "metadata": {},
   "source": [
    "# K-means\n",
    "\n",
    "In this notebook, we will explore the k-means algorithm in its simplest form.\n",
    "The data can be generated as in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vblA",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,centers = make_blobs(\n",
    "    n_samples=1000,\n",
    "    n_features=2,\n",
    "    return_centers=True,\n",
    ")\n",
    "\n",
    "#TODO: Shuffle and split the data\n",
    "\n",
    "# Plot the training data\n",
    "plt.scatter(X_train[:,0], X_train[:,1], c=y_train)\n",
    "\n",
    "plt.scatter(centers[:,0], centers[:,1], c='r', s=120)\n",
    "plt.legend([\"data\", \"centers\"])\n",
    "plt.xlabel(r\"$x_1$\")\n",
    "plt.ylabel(r\"$x_2$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bkHC",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "You can proceed in the same way as for KNN. However:\n",
    "- In the constructor, we will save the number of clusters, as well as the maximum number of iterations and the tolerance.\n",
    "- In the fit method, we will:\n",
    "    - Initialize the centroids randomly from the data points\n",
    "    - For each iteration:\n",
    "        - Assign each data point to the nearest centroid\n",
    "        - Update the centroids by taking the mean of the assigned points\n",
    "        - Check for convergence by checking the decrease in loss (sum of squared distances to the nearest centroid)\n",
    "- In the predict method, we will assign each data point to the nearest centroid.\n",
    "\n",
    "Use, as presented in the lecture, matrix $\\gamma$ to keep track of the assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lEQa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class kmeans_demo:\n",
    "    def __init__(self, K, max_iters=200, tol=1e-8):\n",
    "        pass\n",
    "\n",
    "    def fit(self,X):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PKri",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Once this is done, we can instantiate the object and call its `fit` method on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xref",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Instantiate, fit and predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Kclp",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "The obtained solution is **not** the unique solution of the problem. The optimization procedure converges to a __local minimum__. As such, it is sensitive to initial conditions\n",
    "\n",
    "<details>\n",
    "    <summary>What influences the final result?</summary>\n",
    "    The choice of initial values of `C` is the *only* random parameter that we initialize\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary>What can be done about it?</summary>\n",
    "    We could start from different random positions! Then, select the best model out of those we obtained.\n",
    "</details>\n",
    "\n",
    "\n",
    "Create a class that applies k-means several times, and saves the best model (the one with the lowest loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hstk",
   "metadata": {},
   "outputs": [],
   "source": [
    "class kmeans_demo_multiple:\n",
    "    def __init__(self, K, repeats=10, max_iters=200, tol=1e-8):\n",
    "        self.K = K\n",
    "        self.repeats = repeats\n",
    "        self.max_iters=max_iters\n",
    "        self.tol=tol\n",
    "\n",
    "# TODO: Implement the required methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nWHF",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ROlb",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## How to know which $K$ to use?\n",
    "\n",
    "So far, we assumed that we have a reasonable intuition for `K`. But it may not be the case.\n",
    "Let us create a new example, with more centroids, and this time plot it without the labels. See if you can guess the true number of centroids (which is 5).\n",
    "\n",
    "Tip: run the following cell several time, as it will produce always a different result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qnkX",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2,y2 = make_blobs(\n",
    "    n_samples=1000,\n",
    "    n_features=2,\n",
    "    centers=5\n",
    ")\n",
    "plt.scatter(X2[:,0], X2[:,1])\n",
    "plt.legend([\"data\"])\n",
    "plt.xlabel(r\"$x_1$\")\n",
    "plt.ylabel(r\"$x_2$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TqIu",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "In those cases, we can proceed in the following way:\n",
    "\n",
    "- select a set of possible values for `K`\n",
    "- fit k-means with each of them and keep track of the error\n",
    "- plot the error for each `K`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Vxnm",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ks = [2,3,4,5,6,7,8,9,10]\n",
    "errors = []\n",
    "\n",
    "for k in Ks:\n",
    "    m = kmeans_demo_multiple(K=k, repeats=20)\n",
    "    m.fit(X2)\n",
    "    errors.append(m.error)\n",
    "\n",
    "plt.plot(Ks, errors)\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DnEU",
   "metadata": {},
   "source": [
    "In most cases, it is possible to empirically observe how after a certain value of `K`, further increases lead to marginal decrease in the error\n",
    "\n",
    "<details>\n",
    "<summary>What is the maximal value for K?</summary>\n",
    "The maximal value for K is the number of data points.\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>Why? What happens at the maximal value for K?</summary>\n",
    "If K is equal to the number of data points, there exist one centroid for each data point. Any additional centroid would never receive any affiliation because of that.\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>What about the error?</summary>\n",
    "If K is equal to the number of data points, the error is 0, because each centroid is overlapping with its respective data point, and therefore there is no error</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
